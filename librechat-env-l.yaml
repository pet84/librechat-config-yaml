version: 1.2.4
cache: true

interface:
  customWelcome: "üåü V√≠tej, {{user.name}} üëã Jsem Airis"

  termsOfService:
    modalContent: |
      # Podm√≠nky slu≈æby
      ## √övod
      V√≠tejte v AIRIS ArchEnergy Chat!  
      Pou≈æ√≠v√°n√≠m t√©to slu≈æby souhlas√≠te s n√°sleduj√≠c√≠mi pravidly:
      - Slu≈æba je poskytov√°na ‚Äûtak jak je".

      - AIRIS ArchEnergy nenese odpovƒõdnost za rozhodnut√≠ uƒçinƒõn√° na z√°kladƒõ v√Ωstup≈Ø AI.
      - U≈æivatel souhlas√≠, ≈æe AI m≈Ø≈æe dƒõlat chyby.

      ## Z√°vƒõr
      Pokud nesouhlas√≠te s tƒõmito podm√≠nkami, slu≈æbu nepou≈æ√≠vejte.

  privacyPolicy:
    modalContent: |
      # Z√°sady ochrany osobn√≠ch √∫daj≈Ø
      ## Ochrana dat
      Va≈°e soukrom√≠ je pro n√°s d≈Øle≈æit√©.  
      Data konverzac√≠ nejsou sd√≠lena s t≈ôet√≠mi stranami mimo poskytovatele AI API.

      - Osobn√≠ √∫daje uchov√°v√°me jen v nezbytn√©m rozsahu.
      - U≈æivatel m≈Ø≈æe kdykoliv po≈æ√°dat o smaz√°n√≠ √∫ƒçtu.

      ## Kontakt
      V p≈ô√≠padƒõ dotaz≈Ø n√°s kontaktujte na [archenergy.cz](https://archenergy.cz).

registration:
  socialLogins:
    - "google"

endpoints:
  openAI:
    titleConvo: true
@@ -49,7 +40,6 @@ endpoints:
          label: "ChatGPT 4o Mini"
    fetch: false
    modelDisplayLabel: "ChatGPT"

  google:
    titleConvo: true
    titleModel: gemini-2.5-flash
@@ -65,38 +55,36 @@ endpoints:
          label: "Gemini 2.5 Flash Lite"
    fetch: false
    modelDisplayLabel: "Google Gemini"

  anthropic:
    titleConvo: true
    titleModel: claude-3-5-sonnet-20241022
    summarize: false
    summaryModel: claude-3-5-sonnet-20241022
    models:
      default:
        - id: claude-3-5-sonnet-20241022
          label: "Claude 3.5 Sonnet"
        - id: claude-3-5-haiku-20241022  
          label: "Claude 3.5 Haiku"
        - id: claude-3-opus-20240229
          label: "Claude Opus"




    fetch: false
    modelDisplayLabel: "Anthropic Claude"

speech:
  # V√Ωchoz√≠ nastaven√≠ pro u≈æivatele
  speechTab:
    conversationMode: true
    advancedMode: false
    speechToText:
      engineSTT: "external"
      languageSTT: "Czech (CZ)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "nova"                 # V√Ωchoz√≠ hlas Nova
      languageTTS: "cs"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true
@@ -107,9 +95,9 @@ speech:
      apiKey: "${OPENAI_API_KEY}"
      model: "whisper-1"

  # Text-to-Speech (TTS) - OpenAI TTS s Nova jako v√Ωchoz√≠
  tts:
    openai:
      apiKey: "${OPENAI_API_KEY}"
      model: "tts-1"
      voices: ["nova", "alloy", "echo", "fable", "onyx", "shimmer"]  # Nova je prvn√≠ = v√Ωchoz√≠      models:
        # List of default models to use. At least one value is required.
        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']
        # Fetch option: Set to true to fetch models from API.
        fetch: true # Defaults to false.
 
      # Optional configurations
 
      # Title Conversation setting
      titleConvo: true # Set to true to enable title conversation
 
      # Title Method: Choose between "completion" or "functions".
      # titleMethod: "completion"  # Defaults to "completion" if omitted.
 
      # Title Model: Specify the model to use for titles.
      titleModel: 'mistral-tiny' # Defaults to "gpt-3.5-turbo" if omitted.
 
      # Summarize setting: Set to true to enable summarization.
      # summarize: false
 
      # Summary Model: Specify the model to use if summarization is enabled.
      # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.
 
      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
      # forcePrompt: false
 
      # The label displayed for the AI model in messages.
      modelDisplayLabel: 'Mistral' # Default is "AI" when not set.
 
      # Add additional parameters to the request. Default params will be overwritten.
      # addParams:
      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/
 
      # Drop Default params parameters from the request. See default params in guide linked below.
      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']
 
    # OpenRouter Example
    - name: 'OpenRouter'
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.
      apiKey: '${OPENROUTER_KEY}'
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        default: ['meta-llama/llama-3-70b-instruct']
        fetch: true
      titleConvo: true
      titleModel: 'meta-llama/llama-3-70b-instruct'
      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.
      dropParams: ['stop']
      modelDisplayLabel: 'OpenRouter'
 
# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
# See the Custom Configuration Guide for more information:
# https://www.librechat.ai/docs/configuration/librechat_yaml
