version: 1.2.8
cache: true

endpoints:
  custom:
    - name: "OpenAI"
      apiKey: "${OPENAI_API_KEY}"
      baseURL: "https://api.openai.com/v1"
      titleConvo: true
      titleModel: "gpt-4o-mini"
      summarize: false
      models:
        "gpt-4o-mini":
          modelDisplayLabel: "GPT-4o Mini"
      fetch: false
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: ["gpt-3.5-turbo"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "current_model"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"
    - name: "Ollama"
      apiKey: "ollama"
      baseURL: "http://host.docker.internal:11434/v1/"
      models:
        default: [
          "llama3:latest",
          "command-r",
          "mixtral",
          "phi3"
          ]
        fetch: true # fetching list of models is not supported
      titleConvo: true
      titleModel: "current_model"
